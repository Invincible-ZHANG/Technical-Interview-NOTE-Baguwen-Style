---
title: "并行计算基础"
date: 2025-09-10
categories: gpu_cuda
layout: note
excerpt: "OPENMP + MPI + 向量化"
---

>学习路线，先学习OPENMP，之后学习MPI。



## 1.什么是并行计算

并行计算是一种通过将任务分解为多个子任务并同时在多个处理器或计算节点上执行的计算方式。它的主要目标是提高计算速度和效率，解决那些单一处理器难以快速处理的大规模问题。简而言之就是充分动用服务器硬件资源，将很大计算量的问题分解给不同的核心完成一部分，最终所有核心协作完成所有任务，以起到加速程序运行的效果。

**并行计算的核心内容：计算任务分解、内存访问模型、并行单元间的通信（MPI）**。



## 2.并行计算的基本概念

* 并行性与并发性:
  * 并行性指的是多个任务在同一时间同时执行。
  * 并发性指的是多个任务在系统中交替进行，但这些任务并不一定同时运行。
* 任务划分：
  * 负载均衡：确保任务均匀地分配到所有处理器或核心，避免某些处理器过载而其他处理器闲置。
  * 任务粒度：选择适当的任务粒度，以平衡任务的管理开销和计算效率。粒度过细可能导致管理开销过高，粒度过粗可能导致负载不均。
  * 通信开销：尽量减少处理器之间的数据交换，优化数据局部性，以降低通信开销。
  * 同步开销：减少不同任务之间的同步需求，避免不必要的等待和阻塞。
  * 可扩展性：确保任务划分策略能够适应处理器数量的增加，保持系统性能的可扩展性。
* 并行架构（共享内存与分布式内存）
  * 共享内存架构（对应 OpenMP）：所有处理器共享同一块物理内存。处理器可以直接访问和修改共享的数据。数据共享和同步机制较为直接，不需要显式通信操作。
  * 分布式内存架构（对应 MPI）：每个处理器或计算节点有独立的内存空间。处理器之间通过消息传递进行数据交换。数据交换和通信需要显式管理。
  （举例：翻译100页，每个小组10页，但是10和11有内容想关，必须知道信息，涉及到传输）



## 3.OpenMP

1）OpenMP 概述
* 什么是 OpenMP？
  * OpenMP（Open Multi-Processing）是一种应用程序接口（API），用于在共享内存的多处理器系统上进行并行编程。它通过在代码中添加指令（pragmas）的方式，让程序员能够简单地将串行代码并行化，而不需要深入底层硬件或复杂的多线程管理。OpenMP 支持 C、C++ 和 Fortran 等语言。
* 适用场景：共享内存并行模型

2）OpenMP 编程模型
* 共享内存模型
  * 共享内存模型指的是所有线程在同一个地址空间中共享数据。这意味着不同线程可以访问相同的内存位置，并且可以共享变量的值。
  * 共享变量：在并行区域中，默认情况下，大多数变量是共享的，即所有线程都可以访问和修改这些变量的值。
  * 私有变量：某些情况下，我们可能希望每个线程拥有变量的私有副本，这样不同线程之间不会相互干扰。OpenMP 通过 private 指令指定这些变量。
  * 数据竞争（Race Condition）：由于多个线程同时访问和修改共享变量，可能会导致数据竞争问题。为了避免这种情况，OpenMP 提供了同步机制，如 critical 和 atomic 等。
* 并行区域（Parallel Region）
  * 并行区域是 OpenMP 编程的核心概念。它是由编译器指令#pragma omp parallel 指定的一段代码，告诉 OpenMP 在这段代码中创建多个线程并行执行。


3）OpenMP 基本指令

* #pragma omp parallel
  * 定义一个并行区域，启动多个线程并行执行该区域中的代码。
```
  #pragma omp parallel
{
    // 并行执行的部分
}
```
* #pragma omp parallel for
  * 将循环的迭代分配给多个线程并行执行。

* #pragma omp single
  * 指定代码块只由第一个到达线程执行，其他线程跳过该代码块。





## Reference

https://xflops.sjtu.edu.cn/hpc-start-guide/parallel-computing/basic/