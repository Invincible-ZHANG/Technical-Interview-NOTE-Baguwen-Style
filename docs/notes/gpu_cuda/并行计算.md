---
title: "并行计算基础"
date: 2025-09-10
categories: gpu_cuda
layout: note
excerpt: "OPENMP + MPI + 向量化"
---

>学习路线，先学习OPENMP，之后学习MPI。



## 1.什么是并行计算

并行计算是一种通过将任务分解为多个子任务并同时在多个处理器或计算节点上执行的计算方式。它的主要目标是提高计算速度和效率，解决那些单一处理器难以快速处理的大规模问题。简而言之就是充分动用服务器硬件资源，将很大计算量的问题分解给不同的核心完成一部分，最终所有核心协作完成所有任务，以起到加速程序运行的效果。

**并行计算的核心内容：计算任务分解、内存访问模型、并行单元间的通信（MPI）**。



## 2.并行计算的基本概念

* 并行性与并发性:
  * 并行性指的是多个任务在同一时间同时执行。
  * 并发性指的是多个任务在系统中交替进行，但这些任务并不一定同时运行。
* 任务划分：
  * 负载均衡：确保任务均匀地分配到所有处理器或核心，避免某些处理器过载而其他处理器闲置。
  * 任务粒度：选择适当的任务粒度，以平衡任务的管理开销和计算效率。粒度过细可能导致管理开销过高，粒度过粗可能导致负载不均。
  * 通信开销：尽量减少处理器之间的数据交换，优化数据局部性，以降低通信开销。
  * 同步开销：减少不同任务之间的同步需求，避免不必要的等待和阻塞。
  * 可扩展性：确保任务划分策略能够适应处理器数量的增加，保持系统性能的可扩展性。
* 并行架构（共享内存与分布式内存）
  * 共享内存架构（对应 OpenMP）：所有处理器共享同一块物理内存。处理器可以直接访问和修改共享的数据。数据共享和同步机制较为直接，不需要显式通信操作。
  * 分布式内存架构（对应 MPI）：每个处理器或计算节点有独立的内存空间。处理器之间通过消息传递进行数据交换。数据交换和通信需要显式管理。
  （举例：翻译100页，每个小组10页，但是10和11有内容想关，必须知道信息，涉及到传输）



## 3.OpenMP

1）OpenMP 概述
* 什么是 OpenMP？
  * OpenMP（Open Multi-Processing）是一种应用程序接口（API），用于在共享内存的多处理器系统上进行并行编程。它通过在代码中添加指令（pragmas）的方式，让程序员能够简单地将串行代码并行化，而不需要深入底层硬件或复杂的多线程管理。OpenMP 支持 C、C++ 和 Fortran 等语言。
* 适用场景：共享内存并行模型

2）OpenMP 编程模型
* 共享内存模型
  * 共享内存模型指的是所有线程在同一个地址空间中共享数据。这意味着不同线程可以访问相同的内存位置，并且可以共享变量的值。
  * 共享变量：在并行区域中，默认情况下，大多数变量是共享的，即所有线程都可以访问和修改这些变量的值。
  * 私有变量：某些情况下，我们可能希望每个线程拥有变量的私有副本，这样不同线程之间不会相互干扰。OpenMP 通过 private 指令指定这些变量。
  * 数据竞争（Race Condition）：由于多个线程同时访问和修改共享变量，可能会导致数据竞争问题。为了避免这种情况，OpenMP 提供了同步机制，如 critical 和 atomic 等。
* 并行区域（Parallel Region）
  * 并行区域是 OpenMP 编程的核心概念。它是由编译器指令#pragma omp parallel 指定的一段代码，告诉 OpenMP 在这段代码中创建多个线程并行执行。


3）OpenMP 基本指令

* #pragma omp parallel
  * 定义一个并行区域，启动多个线程并行执行该区域中的代码。
```
  #pragma omp parallel
{
    // 并行执行的部分
}
```
* #pragma omp parallel for
  * 将循环的迭代分配给多个线程并行执行。

* #pragma omp single
  * 指定代码块只由第一个到达线程执行，其他线程跳过该代码块。


4) OpenMP 中的同步机制
* #pragma omp critical
  * 定义一个临界区，保证代码块在同一时刻只被一个线程执行，以防止竞争条件。
* pragma omp barrier  
  * 强制所有线程在此处同步，确保所有线程都执行到这一步后，才继续执行后续代码。

5) 变量的作用域
* shared：默认情况下，并行区域外申明的变量在并行区域中是共享的，可以使用 shared 子句显式指定变量为共享的。
  ```
  int a;
  #pragma omp parallel for shared(a)
  for (int i = 0; i < n; i++) {
      // a为公有变量
  }
  ```
* private：每个线程在并行区域中有自己独立的变量副本，线程之间相互独立，互不干扰。并行区域内申明的变量默认为私有的，并行区域外申明的变量需要显式申明 private
  ```
  int a;
  #pragma omp parallel for private(a)
  for (int i = 0; i < n; i++) {
      int b;
      //a,b均为私有变量
  }
  ```
* reduction： 用于将每个线程的私有变量在并行区域结束时进行归约（如求和、求最大值等），最终将结果存储到共享变量中。
  ```
  int sum = 0;
  #pragma omp parallel for reduction(+:sum)
  for (int i = 0; i < 10; i++) {
      sum += i;
  }
  ```
6) 调度方法
* static：静态调度将循环的迭代均匀分配给所有线程，并且相邻的迭代会被分配在同一个线程，分配方式在程序开始执行时就已经确定。
  ```
  #pragma omp parallel for schedule(static, 3)
  for (int i = 0; i < n; i++) {
      // 每个线程执行3个连续的迭代
  }
  ```
* dynamic：动态调度在执行时分配迭代，每当一个线程完成当前分配的迭代时，它会动态获取下一个块的迭代。

* guided：引导调度是一种动态调度的变体，但块大小（chunk size）随着任务的完成而逐渐减小。

* auto：自动调度将调度策略的选择权交给编译器或运行时库，由它们决定最佳的调度方式。

* runtime：运行时调度允许在程序运行时通过环境变量设置调度策略。

7) 环境变量
* OMP_SCHEDULE：负责规定调度方式。
* OMP_NUM_THREADS：设置执行期间要使用的最大线程数。
* OMP_PROC_BIND：启用或禁用线程绑定到处理器。有效值为 TRUE 或 FALSE。
* OMP_STACKSIZE：控制创建（非主）线程的堆栈大小。



## 4. MPI

1） MPI 概述
* 什么是 MPI？
  * MPI（Message Passing Interface，消息传递接口）为在分布式内存架构下的进程间通信提供了规范和库支持。在程序的角度，MPI 就是一系列函数接口，他们可以实现不同进程（不同内存区域）之间的消息传递
* 适用场景：分布式内存并行模型





## Reference

https://xflops.sjtu.edu.cn/hpc-start-guide/parallel-computing/basic/